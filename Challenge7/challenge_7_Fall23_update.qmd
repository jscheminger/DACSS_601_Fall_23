---
title: "Challenge_7: Concepts and Practices of Research Design for a Data Science Project"
author: "Jeff Scheminger"
description: "Solutions"
date: "11/27/2023"
format:
  html:
    df-print: paged
    css: "styles.css"
    embed-resources: true
    self-contained-math: true
categories:
  - weekly_challenges
  - challenge_7
---

**Make sure you change the author's name in the above YAML header.**

## Setup

If you have not installed the following packages, please install them before loading them.

```{r}
#| label: setup
#| warning: false
#| message: false

library(tidyverse)
library(readxl)
library(haven) #for loading other datafiles (SAS, STATA, SPSS, etc.)
library(stringr) # if you have not installed this package, please install it.
library(ggplot2) # if you have not installed this package, please install it.
library(lubridate)
library(readr)
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

## Challenge Overview

In this challenge, we will apply the knowledge about research design and other topics covered in lectures so far to the dataset presented.

There will be coding components and writing components. Please read the instructions for each part and complete your challenges.

## Part 1. Choose one of the following datasets to do a simple practice of research design and hypothesis testing (50%)

Dataset 1: The General Social Survey (2022). You can find more information about this data project at <https://gss.norc.org/About-The-GSS>. A codebook explaining the definition of each variable and column is also included.

Dataset 2: The Covid-19 Reports in Massachusetts. The datasets are stored in an Excel file of multiple sheets. You can find more information about this data project in the "Introduction", "Definition", "Notes", and "Data Dictionary" tabs in the Excel file.

1.  **Read the data you choose in R. (5%)**

    For GSS, there is only one data sheet (.dta).

    For the MA Covid-19 reports, you can choose **one of the four datasheets(tabs in Excel)** to read ("Weekly Cases and Deaths", "Case and Death Demographics", "County Data", and "City and Town Data").

```{r}
#type your code here
 Covid19_maweek <- read_excel("_data/covid-19-dashboard-11-16-23.xlsx", sheet = "WkCaseDeath")
View(Covid19_maweek)
as_tibble(Covid19_maweek)
names(Covid19_maweek)[5] ="AllDeaths"
names(Covid19_maweek)[8] ="AllCases"
names(Covid19_maweek)[2] ="WeekEnd"
Covid19_maweek$WeekEnd <- ymd(Covid19_maweek$WeekEnd)
str(Covid19_maweek)

```

2.  **Answer the following questions.**

    \(1\) what is the structure (dimension) of the data? **(2.5%)**

    ```{r}
    #type your code here
# 1. Structure of the data:
#  Data has 195 observations and 9 variables   
# tibble [195 × 9] (S3: tbl_df/tbl/data.frame)
# $ Week Start Date : POSIXct[1:195], format: "2023-01-08" "2021-10-17" ...
# $ WeekEnd         : Date[1:195], format: "2023-01-14" "2021-10-23" ...
# $ Confirmed deaths: num [1:195] 132 79 153 85 654 74 417 67 53 66 ...
# $ Probable deaths : num [1:195] 47 4 15 2 23 2 47 1 9 15 ...
# $ AllDeaths       : num [1:195] 179 83 168 87 677 76 464 68 62 81 ...
# $ Confirmed cases : num [1:195] 7075 8163 18177 9316 12145 ...
# $ Probable cases  : num [1:195] 1645 699 1003 748 30 ...
# $ AllCases        : num [1:195] 8720 8862 19180 10064 12175 ...
# $ Last updated    : POSIXct[1:195], format: "2023-11-16" "2023-11-16" ...
#2. The unit of observation is based on:
#    Weekly counts of COVID 19 deaths and cases in Massachusetts from Feb2020 until
#    Nov2023. There are three "counts" for deaths/cases - confirmed, probable, and
#    all.
    
       
    ```

    \(2\) what is the unit of observation? **(2.5%)**

3.  **Read the overview introduction, codebook (for the GSS data), and other related information about the data (for the Covid-19 data). Now browse the data loaded in R, it seems like there are many different questions this data can answer.** **Based on the class lecture and KKV's reading about "good research questions", please propose ONE research question that can be answered using this data. (5%)**

4.  **Based on the research question you proposed above, propose a hypothesis about a possible relationship between two items. (5%)**

5.  **Based on the hypothesis proposed, please select variables/columns in the data to measure the corresponding concepts in the hypothesis statement. You should select at least one variable/column to measure each concept.**

    **You should also specify which variables/columns you choose and explain why they are the proper ones to measure the concepts. (10%)**

    **Instruction:** Don't just answer, "They are reliable and valid". Instead, you should discuss more why they are reliable (can consistently produce the same results regardless of the same results regardless different times and contexts) and valid (why it is better than other possible or alternative variables/columns). You can find the concepts of validity and reliability in the Nov 20 lecture and the slides (p23-25). There are also more in-depth introductions online, such as [this page](http://media.acc.qcc.cuny.edu/faculty/volchok/Measurement_Volchok/Measurement_Volchok6.html).

6.  **Use the code we learned in the previous week to conduct descriptive statistics for the two variables/columns you selected above. You should present the following information in your descriptive statistics: range, average, standard deviation, the number of NAs, and the number of unique values. (5%)**

    ```{r}
    #type your code here
  # 3. Research Question:
# After several years, the COVID19 virus is still causing illness and death. With the advent of new vaccines and better treatments for those with the virus, have deaths from the disease reached a stable percentage in Massachusetts?
# 
  # 4. Hypothesis about relationship of two variables:
# If we compare confirmed cases reported with confirmed deaths reported from COVID19 over the timeline since its beginning (February 2020) we should be able to examine a ratio between deaths and cases for each week to see if this ratio has stabilized.
  # 5. Variables to be Measured:
# The MA Dept of Public Health has tracked COVID19 since February of 2020. There are many detailed data sets that provide insight into the demographics of the commonwealth’s counties, cities, towns, racial makeup and age information. 
# The weekly counts of cases and death will be used for this analysis. In this data set, cases and deaths have three possible values based on how they were categorized: 
# COVID Cases: Confirmed, Probable, and Confirmed and Probable
# COVID Deaths: Confirmed, Probable, and Confirmed and Probable
# For the analysis I will be using only the confirmed counts, as their DPH definitions are very specific. A person with a positive molecular test for COVID19 is the definition of a confirmed case. A COVID19 confirmed death is a person who has COVID-19 or an equivalent term listed on the death certificate. The data provided by the DPH can produce reliable follow-on analysis as the counts and dates are very specific. I believe that using the confirmed case and death data is a valid choice as the definitions of each count are well defined.
  
    #6. Descriptive Statistics for 
    
    #   Confirmed Cases
 # Range
range_values <- range(Covid19_maweek$`Confirmed cases`)
print(paste("Range:", range_values))
# "Range: 1"      "Range: 162720"

# Average (Mean)
average_value <- mean(Covid19_maweek$`Confirmed cases`, na.rm = TRUE)
print(paste("Average:", average_value))
# "Average: 10662.7897435897"

# Standard Deviation
std_dev_value <- sd(Covid19_maweek$`Confirmed cases`, na.rm = TRUE)
print(paste("Standard Deviation:", std_dev_value))
# "Standard Deviation: 17876.9332027033"

# Count of NA values
na_count <- sum(is.na(Covid19_maweek$`Confirmed cases`))
print(paste("Count of NA values:", na_count))
#"Count of NA values: 0"

# Count of Unique values
unique_count <- length(unique(Covid19_maweek$`Confirmed cases`))
print(paste("Count of Unique values:", unique_count))
# "Count of Unique values: 194"

    #   Confirmed Deaths

# Range
range_values <- range(Covid19_maweek$`Confirmed deaths`)
print(paste("Range:", range_values))
#"Range: 0"    "Range: 1210"

# Average (Mean)
average_value <- mean(Covid19_maweek$`Confirmed deaths`, na.rm = TRUE)
print(paste("Average:", average_value))
"Average: 118.041025641026"

# Standard Deviation
std_dev_value <- sd(Covid19_maweek$`Confirmed deaths`, na.rm = TRUE)
print(paste("Standard Deviation:", std_dev_value))
#"Standard Deviation: 184.086007349922"

# Count of NA values
na_count <- sum(is.na(Covid19_maweek$`Confirmed deaths`))
print(paste("Count of NA values:", na_count))
# "Count of NA values: 0"

# Count of Unique values
unique_count <- length(unique(Covid19_maweek$`Confirmed deaths`))
print(paste("Count of Unique values:", unique_count))    
#"Count of Unique values: 118"

    ```

7.  **Plot one univariate graph for each of the variables/columns. (5%)**

    ```{r}
    #type your code here
 
ggplot(Covid19_maweek, aes(x = `WeekEnd`, y = `Confirmed cases`)) +
  geom_bar(stat = "identity", position = "dodge", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Confirmed Cases by WeekEnd", x = "WeekEnd", y = "Confirmed Cases") +
  theme_minimal()    
       
ggplot(Covid19_maweek, aes(x = `WeekEnd`, y = `Confirmed deaths`)) +
  geom_bar(stat = "identity", position = "dodge", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Confirmed Deaths by WeekEnd", x = "WeekEnd", y = "Confirmed Deaths") +
  theme_minimal()
    
    
    ```

8.  **Finally, plot a graph to visually test the hypothesis you propose. Based on the visual evidence, do you see any potential correlation between the two variables? (10%)**

    ```{r}
    #type your code here
    
    # create new variable for pct of confirmed deaths/confirmed cases
    
   Covid19_maweek$Pct_Deaths <- Covid19_maweek$`Confirmed deaths` / Covid19_maweek$`Confirmed cases` 
    
    ggplot(Covid19_maweek, aes(x = WeekEnd, y = Pct_Deaths)) +
  geom_smooth(color = "blue") +
  labs(title = "Line Plot of % Covid Deaths/Cases over Time", x = "Week Ending", y = "% Deaths/Cases") +
  theme_minimal()
    
  # Using geom_line it was not immediately clear that a correlation exists; I was hoping for a smoother "flat" line that would indicate steady state. I then used the geom_smooth which helped understand the correlation better. 
  # It does appear that there was a relatively steady rate in 21-22, it flattens out again 22-23, but at a higher rate. 
  # I would have expected that more vaccines and treatments would have kept recent rates lower.
    
    ```

## Part 2. Reviewing the findings of a graph by examining the raw data.

This part of the challenge is based on a scenario. Suppose you are a data scientist who provides consulting services to the government. One day, your client asks you to investigate an article by the New York Times that reported on some research on people's confidence in the institutions of democracy. It had been published in an academic journal. The headline in the Times ran, ["How Stable Are Democracies? 'Warning Signs Are Flashing Red'" (Taub, 2016)](https://www.nytimes.com/2016/11/29/world/americas/western-liberal-democracy.html). The graph accompanying the article, as shown below, plots people's responses to a question in the World Value Survey (WVS) (V162-Importance of democracy). The graph certainly seemed to show an alarming decline. The graph was widely circulated on social media. It's an elegant small-multiple that, in addition to the point ranges it identifies, also shows an error range (labeled as such for people who might not know what it is), and the story told across the panels for each country is pretty consistent.

![](https://socviz.co/assets/ch-01-democracy-nyt-version.png){fig-align="center" width="1000"}

1.  **Please briefly describe the major findings of this graph. (5%)**

2.  **Your client is concerned about the findings of this graph.** On the one hand, they are surprised and worried by the "crisis of democracy" presented in this graph**. On the other hand, they also doubt the argument of the NYT article and the validity of the findings of this graph.** Before deciding on making any policy to respond, they ask you to conduct some additional research with the original data.

    \(1\) Read the provided WVS data. The dataset is large, so you must subset it before analyzing it. **Please keep only the following columns: respondents' country(V2), age(V236), and the question for plotting (V162).** You also need to filter only the observations in the six countries mentioned above: Sweden, Australia, Netherlands, United States, New Zealand, and Britain/United Kingdom. **(10%)**

    Note: all the columns, including those that are measured categorically, are represented by numbers. You must check out the WVS5 codebook to identify what the numerical values mean (especially for V2-country, see p57 of the codebook).

    ```{r}
    #read the dataset
install.packages("dplyr")
library(dplyr)
    
    
    WVS_file <- read_rds('_data/WVS5.rds')
    WVS_subset <- WVS_file[, c("V2", "V236", "V162")]
    values_to_keep <- c(36, 752, 554, 840, 528, 826)
    WVS_filter <- WVS_subset[WVS_subset$V2 %in% values_to_keep, ]
    
    
    
    
    
    ```

    \(2\) Conduct descriptive statistics to show these three columns' unique values, means, ranges, and numbers of NA. You can plot univariate graphs as we did in challenge#4 or apply the summary statistics function as in challenge#3. Just do either approach. **(10%）**

    ```{r}
    #type your code here
  
    # Statistics for V2 - Country/Region  
    
  # Range
range_values <- range(WVS_filter$V2)
print(paste("Range:", range_values))
#"Range: 36"    "Range: 840"

# Average (Mean)
average_value <- mean(WVS_filter$V2, na.rm = TRUE)
print(paste("Average:", average_value))
"Average: 565.250669842215"

# Count of NA values
na_count <- sum(is.na(WVS_filter$V2))
print(paste("Count of NA values:", na_count))
# "Count of NA values: 0"

# Count of Unique values
unique_count <- length(unique(WVS_filter$V2))
print(paste("Count of Unique values:", unique_count))    
#"Count of Unique values: 6"  

   # Statistics for V236 - Year of Birth  
    
  # Range
range_values <- range(WVS_filter$V236)
print(paste("Range:", range_values))
#"Range: -2"    "Range: 1991"

# Average (Mean)
average_value <- mean(WVS_filter$V236, na.rm = TRUE)
print(paste("Average:", average_value))
"Average: 1946.52560285799"

# Count of NA values
na_count <- sum(is.na(WVS_filter$V236))
print(paste("Count of NA values:", na_count))
# "Count of NA values: 0"

# Count of Unique values
unique_count <- length(unique(WVS_filter$V236))
print(paste("Count of Unique values:", unique_count))    
#"Count of Unique values: 80"

   # Statistics for V162 - Importance of Democracy  
    
  # Range
range_values <- range(WVS_filter$V162)
print(paste("Range:", range_values))
#"Range: -5"    "Range: 10"

# Average (Mean)
average_value <- mean(WVS_filter$V162, na.rm = TRUE)
print(paste("Average:", average_value))
"Average: 6.87139029473057"

# Count of NA values
na_count <- sum(is.na(WVS_filter$V162))
print(paste("Count of NA values:", na_count))
# "Count of NA values: 0"

# Count of Unique values
unique_count <- length(unique(WVS_filter$V162))
print(paste("Count of Unique values:", unique_count))    
#"Count of Unique values: 14"
    
    ```

    \(3\) (Optional) Please replicate the graph of the NYT article.

    ```{r}
    #type your code here
    ```

    \(4\) Now, please plot a graph to show the relationship between the decades of birth (x-axis) and the average level of the response scores to the question "importance of democracy" (y-axis) for each of the six countries. You can use facet_grid or facet_wrap to combine multiple graphs into a matrix of panels. **(15%)**

    ```{r}
    #type your code here
  values_to_keep <- c(840)

# Create WVS_filtered dataset
  WVS_filterUSA <- WVS_filter[WVS_filter$V2 %in% values_to_keep, ]
  
  ggplot(WVS_filterUSA, aes(x = V236, y = V162)) +
  geom_smooth(method = "loess", se = FALSE, color = "blue") +
  labs(title = "Year of Birth vs Importance of Democracy in USA",
       x = "Year of Birth",
       y = "Importance of Democracy") +
  theme_minimal()
    
    
    ```

3.  **Describe what you find from the graph you made above. Compared to the graph on NYT, what's in common, or what's different? Please type your answer below. (5%)**

4.  **Your client wants to hear your conclusion. Do you agree with the argument presented by the graph and the NYT article? Should we really worry about the decline? This is an op-ed question. Please type your answer below. (5%)**
